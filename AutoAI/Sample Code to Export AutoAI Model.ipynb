{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "< Notebook content above removed >"}, {"metadata": {}, "cell_type": "markdown", "source": "### Get pipeline as scikit-learn pipeline model\n\nAfter you compare the pipelines, download and save a scikit-learn pipeline model object from the\nAutoAI training job.\n\n**Tip:** If you want to get a specific pipeline you need to pass the pipeline name in:\n```\npipeline_optimizer.get_pipeline(pipeline_name=pipeline_name)\n```"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "# In my example scenario, I specifically want Pipeline_2, but you can choose any of them.\n# I'm going to generate two different versions of the model -- one is lale (default) and other is sklearn. This is only for example purposes; you don't need both.\npipeline_model = pipeline_optimizer.get_pipeline(pipeline_name=\"Pipeline_2\")\nsk_pipeline_model = pipeline_optimizer.get_pipeline(pipeline_name=\"Pipeline_2\",astype='sklearn')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Attach to current project to be able to access it's object storage bucket.\n- The project ID is available as `experiment_metadata['project_id']`, or you can also just copy it from the URL of your project in Watson Studio (it will be in the form of \"c4cd6c54-ed6f-752f-84ed-e819e45143eb\")\n- To get the project token, you can generate one in the project's settings (it will be in the form of \"p-826ef51175e4627b2599b6e91664726cdf6aa99f\")"}, {"metadata": {}, "cell_type": "code", "source": "from project_lib import Project\nprojectID = \"c4cd6c54-ed6f-752f-84ed-e819e45143eb\"\nprojectToken = \"p-826ef51175e4627b2599b6e91664726cdf6aa99f\"\nproject = Project(None, projectID, projectToken)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Export the model to a file in the project's object storage bucket (with pickle object serialization)"}, {"metadata": {}, "cell_type": "code", "source": "# This exports the first form of the model (you don't actually need both, just doing this for illustrative purposes)\nimport pickle\nproject.save_data(data=pickle.dumps(pipeline_model),file_name='autoai_iris_model_pickle.bin',overwrite=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# This exports the second form of the model (again, you don't actually need both, just doing this for illustrative purposes)\nimport pickle\nproject.save_data(data=pickle.dumps(sk_pipeline_model),file_name='autoai_iris_sk_model_pickle.bin',overwrite=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "< End of my code. Generated notebook content below this point has been removed >"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "pycharm": {"stem_cell": {"cell_type": "raw", "metadata": {"collapsed": false}, "source": ["\n"]}}}, "nbformat": 4, "nbformat_minor": 1}